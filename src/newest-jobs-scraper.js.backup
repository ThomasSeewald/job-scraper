const puppeteer = require('puppeteer');
const { Pool } = require('pg');
const fs = require('fs');
const path = require('path');
const EmailExtractor = require('./email-extractor');
const IndependentCaptchaSolver = require('./independent-captcha-solver');

// Load configuration
const config = JSON.parse(fs.readFileSync(path.join(__dirname, '../config/database.json'), 'utf8'));
const dbConfig = config.production;

class SimplifiedDetailScraper {
    constructor() {
        this.pool = new Pool(dbConfig);
        this.emailExtractor = new EmailExtractor();
        this.captchaSolver = new IndependentCaptchaSolver();
        this.browser = null;
        this.page = null;
        
        // Configuration
        this.batchSize = 10; // Process 10 jobs at a time
        this.delayBetweenRequests = 2000; // 2 seconds between requests
        this.maxRetries = 2;
    }

    /**
     * Initialize browser and page
     */
    async initializeBrowser() {
        console.log('üöÄ Initializing browser...');
        
        this.browser = await puppeteer.launch({
            headless: false,
            defaultViewport: null,
            args: [
                '--no-sandbox',
                '--disable-setuid-sandbox',
                '--disable-blink-features=AutomationControlled'
            ]
        });

        this.page = await this.browser.newPage();
        
        // Set user agent to appear more human-like
        await this.page.setUserAgent('Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36');
        
        console.log('‚úÖ Browser initialized');
    }

    /**
     * Get jobs that need detail scraping (no external URLs, not yet scraped)
     * Orders by publication date DESC to get newest first, one per employer
     */
    async getJobsToScrape(limit = 50) {
        const query = `
            WITH employers_with_emails AS (
              SELECT DISTINCT arbeitgeber
              FROM arbeitsagentur_jobs_v2 
              WHERE (email IS NOT NULL AND email != '') 
                 OR (new_email IS NOT NULL AND new_email != '')
            ),
            employers_with_job_details AS (
              SELECT DISTINCT j.arbeitgeber
              FROM arbeitsagentur_jobs_v2 j
              INNER JOIN job_details jd ON j.refnr = jd.reference_number
              WHERE jd.has_emails = true
            ),
            employers_with_external_urls AS (
              SELECT DISTINCT arbeitgeber
              FROM arbeitsagentur_jobs_v2 
              WHERE externeurl IS NOT NULL AND externeurl != ''
            ),
            recent_jobs AS (
              SELECT 
                j.id,
                j.refnr,
                j.titel,
                j.arbeitgeber,
                j.arbeitsort_ort,
                j.aktuelleveroeffentlichungsdatum,
                ROW_NUMBER() OVER (PARTITION BY j.arbeitgeber ORDER BY j.aktuelleveroeffentlichungsdatum DESC, j.id DESC) as rn
              FROM arbeitsagentur_jobs_v2 j
              LEFT JOIN job_details jd ON j.refnr = jd.reference_number
              WHERE j.aktuelleveroeffentlichungsdatum >= CURRENT_DATE - INTERVAL '7 days'
                AND j.refnr IS NOT NULL
                AND (j.externeurl IS NULL OR j.externeurl = '')
                AND (j.email IS NULL OR j.email = '')
                AND (j.new_email IS NULL OR j.new_email = '')
                AND jd.reference_number IS NULL
                AND j.arbeitgeber NOT IN (SELECT arbeitgeber FROM employers_with_emails)
                AND j.arbeitgeber NOT IN (SELECT arbeitgeber FROM employers_with_job_details)
                AND j.arbeitgeber NOT IN (SELECT arbeitgeber FROM employers_with_external_urls)
            )
            SELECT 
                id, refnr, titel, arbeitgeber, arbeitsort_ort, aktuelleveroeffentlichungsdatum
            FROM recent_jobs 
            WHERE rn = 1
            ORDER BY aktuelleveroeffentlichungsdatum DESC, refnr DESC
            LIMIT $1
        `;
        
        const client = await this.pool.connect();
        try {
            const result = await client.query(query, [limit]);
            console.log(`üìã Found ${result.rows.length} jobs ready for detail scraping (newest first, one per employer)`);
            return result.rows;
        } finally {
            client.release();
        }
    }

    /**
     * Construct Arbeitsagentur detail URL from reference number
     */
    constructDetailUrl(refnr) {
        return `https://www.arbeitsagentur.de/jobsuche/jobdetail/${refnr}`;
    }

    /**
     * Scrape detail page for a single job
     */
    async scrapeJobDetail(job) {
        const startTime = Date.now();
        let scrapingResult = {
            success: false,
            emails: '',
            bestEmail: '',
            domain: '',
            emailCount: 0,
            captchaSolved: false,
            error: null,
            duration: 0
        };

        try {
            const detailUrl = this.constructDetailUrl(job.refnr);
            console.log(`üîç Scraping: ${job.titel} - ${job.arbeitgeber}`);
            console.log(`üîó URL: ${detailUrl}`);

            // Navigate to detail page
            await this.page.goto(detailUrl, { 
                waitUntil: 'networkidle0',
                timeout: 30000 
            });

            // Check for CAPTCHA
            const captchaDetected = await this.detectAndSolveCaptcha();
            if (captchaDetected) {
                scrapingResult.captchaSolved = true;
                console.log('üîì CAPTCHA solved, continuing...');
            }

            // Wait a bit for page to fully load
            await new Promise(resolve => setTimeout(resolve, 2000));

            // Extract page content
            const html = await this.page.content();
            
            // Check if job doesn't exist
            if (html.includes('Dieses Stellenangebot gibt es nicht oder nicht mehr.')) {
                console.log('‚ùå Job no longer exists - skipping');
                scrapingResult.success = false;
                scrapingResult.error = 'Job no longer exists';
                return scrapingResult;
            }
            
            // Extract emails using our focused email extractor
            const emailResult = this.emailExtractor.extractPrioritizedEmails(
                html, 
                job.titel, 
                job.arbeitgeber
            );

            scrapingResult = {
                ...scrapingResult,
                success: true,
                emails: emailResult.emails,
                bestEmail: emailResult.bestEmail,
                domain: emailResult.domain,
                emailCount: emailResult.emailCount,
                applicationWebsite: emailResult.applicationWebsite || ''
            };

            if (emailResult.emailCount > 0) {
                console.log(`‚úÖ Found ${emailResult.emailCount} emails: ${emailResult.emails}`);
                if (emailResult.bestEmail) {
                    console.log(`üéØ Best email: ${emailResult.bestEmail}`);
                }
            } else if (emailResult.applicationWebsite) {
                console.log(`üåê No emails found, but found application website: ${emailResult.applicationWebsite}`);
                console.log(`üè¢ Domain: ${emailResult.domain}`);
            } else {
                console.log(`‚ùå No emails or application website found`);
            }

        } catch (error) {
            console.error(`‚ùå Error scraping ${job.refnr}:`, error.message);
            scrapingResult.error = error.message;
        }

        scrapingResult.duration = Date.now() - startTime;
        return scrapingResult;
    }

    /**
     * Detect and solve CAPTCHA if present (using production patterns from cron jobs)
     */
    async detectAndSolveCaptcha() {
        const maxRetries = 3;
        
        for (let attempt = 1; attempt <= maxRetries; attempt++) {
            try {
                // Use multiple selector patterns like production code
                const captchaSelectors = [
                    'img[src*="captcha"]',
                    'img[alt*="captcha"]', 
                    'img[alt*="Captcha"]',
                    'img[alt*="CAPTCHA"]',
                    '.captcha img',
                    '#captcha img'
                ];
                
                let captchaImage = null;
                for (const selector of captchaSelectors) {
                    captchaImage = await this.page.$(selector);
                    if (captchaImage) break;
                }
                
                if (!captchaImage) {
                    return false; // No CAPTCHA detected
                }

                console.log(`üîí CAPTCHA detected, solving... (attempt ${attempt}/${maxRetries})`);

                // Extract image URL from DOM (production pattern)
                const captchaImageUrl = await this.page.evaluate(() => {
                    const images = document.querySelectorAll('img');
                    for (const img of images) {
                        if (img.src && (img.src.includes('captcha') || 
                            (img.alt && img.alt.toLowerCase().includes('captcha')))) {
                            return img.src;
                        }
                    }
                    return null;
                });
                
                if (!captchaImageUrl) {
                    console.log('‚ùå Could not extract CAPTCHA image URL from DOM');
                    continue;
                }
                
                console.log(`üñºÔ∏è CAPTCHA image URL: ${captchaImageUrl}`);
                
                // Use the CAPTCHA solver's built-in URL download method
                const solution = await this.captchaSolver.solveCaptchaFromUrl(captchaImageUrl);
                
                if (solution.success) {
                    // Validate solution length (Arbeitsagentur uses 6 characters)
                    if (!solution.text || solution.text.length !== 6) {
                        console.log(`‚ùå Invalid CAPTCHA solution length: ${solution.text?.length} (expected 6 characters)`);
                        continue;
                    }
                    
                    console.log(`üîë CAPTCHA solution: ${solution.text}`);
                    
                    // Use exact production pattern for form submission
                    console.log(`üî§ Entering CAPTCHA solution: '${solution.text}' into input field...`);
                    
                    await this.page.evaluate((captchaSolution) => {
                        var captchaInput = document.getElementById('kontaktdaten-captcha-input');
                        if (captchaInput) {
                            captchaInput.value = '';
                            captchaInput.value = captchaSolution;
                            
                            // Dispatch events to ensure proper detection
                            var inputEvent = new Event('input', { bubbles: true, cancelable: true });
                            var changeEvent = new Event('change', { bubbles: true, cancelable: true });
                            captchaInput.dispatchEvent(inputEvent);
                            captchaInput.dispatchEvent(changeEvent);
                            captchaInput.focus();
                            captchaInput.blur();
                        }
                    }, solution.text);
                    
                    console.log('üî§ CAPTCHA solution entered, waiting before clicking submit...');
                    await new Promise(resolve => setTimeout(resolve, 1000));
                    
                    // Click the specific submit button using production pattern
                    const clicked = await this.page.evaluate(() => {
                        var element = document.querySelector('#kontaktdaten-captcha-absenden-button');
                        if (element) {
                            element.click();
                            return true;
                        }
                        return false;
                    });
                    
                    if (clicked) {
                        console.log('üîò Submit button clicked, waiting for CAPTCHA validation...');
                        await new Promise(resolve => setTimeout(resolve, 3000));
                    } else {
                        console.log('‚ùå Submit button not found');
                        continue;
                    }
                    
                    // Validate using production pattern: check for absence of "sicherheitsabfrage"
                    const pageText = await this.page.evaluate(() => document.body.textContent.toLowerCase());
                    
                    if (!pageText.includes('sicherheitsabfrage')) {
                        console.log(`‚úÖ CAPTCHA solved successfully on attempt ${attempt}!`);
                        return true;
                    } else {
                        console.log(`‚ùå CAPTCHA solution rejected (sicherheitsabfrage still present), retrying... (attempt ${attempt}/${maxRetries})`);
                        if (attempt === maxRetries) {
                            console.log('‚ùå All CAPTCHA attempts failed');
                            return false;
                        }
                        // Continue to next attempt
                    }
                } else {
                    console.log(`‚ùå CAPTCHA solving service failed on attempt ${attempt}: ${solution.error}`);
                    if (attempt === maxRetries) {
                        return false;
                    }
                    // Continue to next attempt
                }
                
            } catch (error) {
                console.log(`‚ùå CAPTCHA handling error on attempt ${attempt}:`, error.message);
                if (attempt === maxRetries) {
                    return false;
                }
                // Continue to next attempt
            }
        }
        
        return false;
    }

    /**
     * Save scraping results to database (job_details + employers table)
     */
    async saveResults(job, scrapingResult) {
        const client = await this.pool.connect();
        
        try {
            await client.query('BEGIN');
            
            // 1. Save to job_details table (for individual job tracking)
            const jobDetailsQuery = `
                INSERT INTO job_details (
                    reference_number,
                    arbeitsagentur_job_id,
                    contact_emails,
                    best_email,
                    company_domain,
                    has_emails,
                    email_count,
                    scraped_at,
                    scraping_duration_ms,
                    captcha_solved,
                    scraping_success,
                    scraping_error,
                    source_url
                ) VALUES ($1, $2, $3, $4, $5, $6, $7, CURRENT_TIMESTAMP, $8, $9, $10, $11, $12)
                ON CONFLICT (reference_number) DO UPDATE SET
                    contact_emails = EXCLUDED.contact_emails,
                    best_email = EXCLUDED.best_email,
                    company_domain = EXCLUDED.company_domain,
                    has_emails = EXCLUDED.has_emails,
                    email_count = EXCLUDED.email_count,
                    scraped_at = CURRENT_TIMESTAMP,
                    scraping_duration_ms = EXCLUDED.scraping_duration_ms,
                    captcha_solved = EXCLUDED.captcha_solved,
                    scraping_success = EXCLUDED.scraping_success,
                    scraping_error = EXCLUDED.scraping_error,
                    source_url = EXCLUDED.source_url
            `;

            const detailUrl = this.constructDetailUrl(job.refnr);
            const jobDetailsValues = [
                job.refnr,
                job.id,
                scrapingResult.emails || null,
                scrapingResult.bestEmail || null,
                scrapingResult.domain || null,
                scrapingResult.emailCount > 0,
                scrapingResult.emailCount,
                scrapingResult.duration,
                scrapingResult.captchaSolved,
                scrapingResult.success,
                scrapingResult.error || null,
                detailUrl
            ];

            await client.query(jobDetailsQuery, jobDetailsValues);

            // 2. Update employers table with website and/or email info
            await this.updateEmployerInfo(client, job.arbeitgeber, scrapingResult);

            await client.query('COMMIT');
            console.log(`üíæ Saved results for ${job.refnr} (job_details + employers)`);
            
        } catch (error) {
            await client.query('ROLLBACK');
            console.error(`‚ùå Database save error for ${job.refnr}:`, error.message);
        } finally {
            client.release();
        }
    }

    /**
     * Update employer information in employers table
     */
    async updateEmployerInfo(client, employerName, scrapingResult) {
        // First, ensure employer exists in employers table
        const ensureEmployerQuery = `
            INSERT INTO employers (name, normalized_name, first_seen, last_updated)
            VALUES ($1, $2, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)
            ON CONFLICT (normalized_name) DO UPDATE SET
                last_updated = CURRENT_TIMESTAMP
            RETURNING id
        `;
        
        const normalizedName = employerName.toLowerCase().trim();
        const employerResult = await client.query(ensureEmployerQuery, [employerName, normalizedName]);
        
        // Update employer with extracted information
        const updateParts = [];
        const updateValues = [];
        let valueIndex = 1;
        
        // Update website if we found one
        if (scrapingResult.applicationWebsite) {
            updateParts.push(`website = $${valueIndex}`);
            updateValues.push(scrapingResult.applicationWebsite);
            valueIndex++;
        }
        
        // Update email info if we found emails
        if (scrapingResult.emailCount > 0) {
            updateParts.push(`contact_emails = $${valueIndex}`);
            updateValues.push(scrapingResult.emails);
            valueIndex++;
            
            updateParts.push(`best_email = $${valueIndex}`);
            updateValues.push(scrapingResult.bestEmail);
            valueIndex++;
            
            updateParts.push(`has_emails = true`);
        }
        
        // Update domain if we have one
        if (scrapingResult.domain) {
            updateParts.push(`company_domain = $${valueIndex}`);
            updateValues.push(scrapingResult.domain);
            valueIndex++;
        }
        
        // Mark that email extraction was attempted
        updateParts.push(`email_extraction_attempted = true`);
        updateParts.push(`email_extraction_date = CURRENT_TIMESTAMP`);
        updateParts.push(`last_updated = CURRENT_TIMESTAMP`);
        
        if (updateParts.length > 0) {
            updateValues.push(normalizedName);
            const updateEmployerQuery = `
                UPDATE employers 
                SET ${updateParts.join(', ')}
                WHERE normalized_name = $${valueIndex}
            `;
            
            await client.query(updateEmployerQuery, updateValues);
            
            const updateType = scrapingResult.applicationWebsite ? 'website' : 'emails';
            console.log(`üè¢ Updated employer "${employerName}" with ${updateType}`);
        }
    }

    /**
     * Process a batch of jobs
     */
    async processBatch(jobs) {
        console.log(`\nüîÑ Processing batch of ${jobs.length} jobs...`);
        
        let successCount = 0;
        let emailsFoundCount = 0;

        for (const job of jobs) {
            try {
                const result = await this.scrapeJobDetail(job);
                await this.saveResults(job, result);

                if (result.success) {
                    successCount++;
                    if (result.emailCount > 0) {
                        emailsFoundCount++;
                    }
                }

                // Delay between requests
                await new Promise(resolve => setTimeout(resolve, this.delayBetweenRequests));

            } catch (error) {
                console.error(`‚ùå Failed to process job ${job.refnr}:`, error.message);
            }
        }

        console.log(`\nüìä Batch completed: ${successCount}/${jobs.length} successful, ${emailsFoundCount} with emails`);
        return { successCount, emailsFoundCount, totalJobs: jobs.length };
    }

    /**
     * Main scraping process
     */
    async startScraping(maxJobs = 100) {
        try {
            console.log('üöÄ Starting Simplified Detail Scraper');
            console.log('üìß Focus: Extract emails and domains only');
            console.log('üö´ Excluded: Jobs with external URLs, arbeitsagentur emails');

            await this.initializeBrowser();

            const jobs = await this.getJobsToScrape(maxJobs);
            
            if (jobs.length === 0) {
                console.log('‚úÖ No jobs found for detail scraping');
                return;
            }

            // Process jobs in batches
            let totalStats = { successCount: 0, emailsFoundCount: 0, totalJobs: 0 };
            
            for (let i = 0; i < jobs.length; i += this.batchSize) {
                const batch = jobs.slice(i, i + this.batchSize);
                const batchStats = await this.processBatch(batch);
                
                totalStats.successCount += batchStats.successCount;
                totalStats.emailsFoundCount += batchStats.emailsFoundCount;
                totalStats.totalJobs += batchStats.totalJobs;

                // Short break between batches
                if (i + this.batchSize < jobs.length) {
                    console.log('‚è∏Ô∏è  Short break between batches...');
                    await new Promise(resolve => setTimeout(resolve, 5000));
                }
            }

            console.log('\nüéâ Scraping completed!');
            console.log(`üìä Final Stats:`);
            console.log(`   Total jobs processed: ${totalStats.totalJobs}`);
            console.log(`   Successful scrapes: ${totalStats.successCount}`);
            console.log(`   Jobs with emails found: ${totalStats.emailsFoundCount}`);
            console.log(`   Success rate: ${((totalStats.successCount / totalStats.totalJobs) * 100).toFixed(1)}%`);
            console.log(`   Email discovery rate: ${((totalStats.emailsFoundCount / totalStats.totalJobs) * 100).toFixed(1)}%`);

        } catch (error) {
            console.error('‚ùå Fatal error:', error.message);
        } finally {
            await this.cleanup();
        }
    }

    /**
     * Clean up resources
     */
    async cleanup() {
        if (this.browser) {
            await this.browser.close();
            console.log('üßπ Browser closed');
        }
        await this.pool.end();
        console.log('üßπ Database connections closed');
    }

    /**
     * Get current statistics
     */
    async getStats() {
        const query = `
            SELECT 
                COUNT(*) as total_scraped,
                COUNT(CASE WHEN has_emails = true THEN 1 END) as with_emails,
                COUNT(CASE WHEN best_email IS NOT NULL THEN 1 END) as with_best_email,
                ROUND(AVG(email_count), 2) as avg_emails_per_job,
                COUNT(DISTINCT company_domain) as unique_domains,
                MAX(scraped_at) as last_scrape
            FROM job_details
            WHERE scraping_success = true
        `;

        const client = await this.pool.connect();
        try {
            const result = await client.query(query);
            return result.rows[0];
        } finally {
            client.release();
        }
    }
}

// CLI interface
async function main() {
    const scraper = new SimplifiedDetailScraper();
    
    const args = process.argv.slice(2);
    const maxJobs = args[0] ? parseInt(args[0]) : 50;

    console.log(`Starting detail scraper for up to ${maxJobs} jobs...`);
    
    try {
        await scraper.startScraping(maxJobs);
    } catch (error) {
        console.error('Fatal error:', error);
        process.exit(1);
    }
}

// Run if called directly
if (require.main === module) {
    main();
}

module.exports = SimplifiedDetailScraper;